{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254693bb-856f-44f8-9510-012186bd7dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "483f0c59-afba-4e96-99bd-c69e4d432ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sts::794038231401:assumed-role/SageMaker-ExecutionRole-20250401T103257/SageMaker\n"
     ]
    }
   ],
   "source": [
    "session = boto3.Session()\n",
    "sts_client = session.client('sts')\n",
    "identity = sts_client.get_caller_identity()\n",
    "print(identity['Arn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76137598-139c-49ef-919d-8380167ae0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock = boto3.client(service_name='bedrock', region_name=\"us-east-1\")\n",
    "bedrock_runtime = boto3.client(service_name='bedrock-runtime', region_name=\"us-east-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "680d56f9-ba2d-46af-91c5-5f1b2f68a448",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon.titan-tg1-large\n",
      "amazon.titan-image-generator-v1:0\n",
      "amazon.titan-image-generator-v1\n",
      "amazon.titan-image-generator-v2:0\n",
      "amazon.nova-premier-v1:0:8k\n",
      "amazon.nova-premier-v1:0:20k\n",
      "amazon.nova-premier-v1:0:1000k\n",
      "amazon.nova-premier-v1:0:mm\n",
      "amazon.nova-premier-v1:0\n",
      "amazon.titan-text-premier-v1:0\n",
      "amazon.nova-pro-v1:0:24k\n",
      "amazon.nova-pro-v1:0:300k\n",
      "amazon.nova-pro-v1:0\n",
      "amazon.nova-lite-v1:0:24k\n",
      "amazon.nova-lite-v1:0:300k\n",
      "amazon.nova-lite-v1:0\n",
      "amazon.nova-canvas-v1:0\n",
      "amazon.nova-reel-v1:0\n",
      "amazon.nova-reel-v1:1\n",
      "amazon.nova-micro-v1:0:24k\n",
      "amazon.nova-micro-v1:0:128k\n",
      "amazon.nova-micro-v1:0\n",
      "amazon.nova-sonic-v1:0\n",
      "amazon.titan-embed-g1-text-02\n",
      "amazon.titan-text-lite-v1:0:4k\n",
      "amazon.titan-text-lite-v1\n",
      "amazon.titan-text-express-v1:0:8k\n",
      "amazon.titan-text-express-v1\n",
      "amazon.titan-embed-text-v1:2:8k\n",
      "amazon.titan-embed-text-v1\n",
      "amazon.titan-embed-text-v2:0:8k\n",
      "amazon.titan-embed-text-v2:0\n",
      "amazon.titan-embed-image-v1:0\n",
      "amazon.titan-embed-image-v1\n",
      "stability.stable-diffusion-xl-v1:0\n",
      "stability.stable-diffusion-xl-v1\n",
      "ai21.jamba-instruct-v1:0\n",
      "ai21.jamba-1-5-large-v1:0\n",
      "ai21.jamba-1-5-mini-v1:0\n",
      "anthropic.claude-instant-v1:2:100k\n",
      "anthropic.claude-instant-v1\n",
      "anthropic.claude-v2:0:18k\n",
      "anthropic.claude-v2:0:100k\n",
      "anthropic.claude-v2:1:18k\n",
      "anthropic.claude-v2:1:200k\n",
      "anthropic.claude-v2:1\n",
      "anthropic.claude-v2\n",
      "anthropic.claude-3-sonnet-20240229-v1:0:28k\n",
      "anthropic.claude-3-sonnet-20240229-v1:0:200k\n",
      "anthropic.claude-3-sonnet-20240229-v1:0\n",
      "anthropic.claude-3-haiku-20240307-v1:0:48k\n",
      "anthropic.claude-3-haiku-20240307-v1:0:200k\n",
      "anthropic.claude-3-haiku-20240307-v1:0\n",
      "anthropic.claude-3-opus-20240229-v1:0:12k\n",
      "anthropic.claude-3-opus-20240229-v1:0:28k\n",
      "anthropic.claude-3-opus-20240229-v1:0:200k\n",
      "anthropic.claude-3-opus-20240229-v1:0\n",
      "anthropic.claude-3-5-sonnet-20240620-v1:0\n",
      "anthropic.claude-3-5-sonnet-20241022-v2:0\n",
      "anthropic.claude-3-7-sonnet-20250219-v1:0\n",
      "anthropic.claude-3-5-haiku-20241022-v1:0\n",
      "anthropic.claude-opus-4-20250514-v1:0\n",
      "anthropic.claude-sonnet-4-20250514-v1:0\n",
      "cohere.command-text-v14:7:4k\n",
      "cohere.command-text-v14\n",
      "cohere.command-r-v1:0\n",
      "cohere.command-r-plus-v1:0\n",
      "cohere.command-light-text-v14:7:4k\n",
      "cohere.command-light-text-v14\n",
      "cohere.embed-english-v3:0:512\n",
      "cohere.embed-english-v3\n",
      "cohere.embed-multilingual-v3:0:512\n",
      "cohere.embed-multilingual-v3\n",
      "deepseek.r1-v1:0\n",
      "meta.llama3-8b-instruct-v1:0\n",
      "meta.llama3-70b-instruct-v1:0\n",
      "meta.llama3-1-8b-instruct-v1:0\n",
      "meta.llama3-1-70b-instruct-v1:0\n",
      "meta.llama3-2-11b-instruct-v1:0\n",
      "meta.llama3-2-90b-instruct-v1:0\n",
      "meta.llama3-2-1b-instruct-v1:0\n",
      "meta.llama3-2-3b-instruct-v1:0\n",
      "meta.llama3-3-70b-instruct-v1:0\n",
      "meta.llama4-scout-17b-instruct-v1:0\n",
      "meta.llama4-maverick-17b-instruct-v1:0\n",
      "mistral.mistral-7b-instruct-v0:2\n",
      "mistral.mixtral-8x7b-instruct-v0:1\n",
      "mistral.mistral-large-2402-v1:0\n",
      "mistral.mistral-small-2402-v1:0\n",
      "mistral.pixtral-large-2502-v1:0\n"
     ]
    }
   ],
   "source": [
    "# bedrock.list_foundation_models()\n",
    "# print the list of foundation models just using the name\n",
    "for model in bedrock.list_foundation_models()['modelSummaries']:\n",
    "    print(model['modelId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66c20fab-185c-4d00-a941-690a1f330110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model ID for Meta Llama 3.2 11B Instruct\n",
    "model_id = 'meta.llama3-2-11b-instruct-v1:0'\n",
    "\n",
    "# Define the user prompt\n",
    "user_prompt = \"What is the capital of France?\"\n",
    "\n",
    "# Format the prompt according to Meta Llama's requirements\n",
    "prompt = f\"<|begin_of_text|><|start_header_id|>user<|end_header_id|> {user_prompt} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\n",
    "\n",
    "# Define the request body with the prompt and optional parameters\n",
    "body = json.dumps({\n",
    "    \"prompt\": prompt,\n",
    "    \"temperature\": 0.5,  # Controls randomness (default is 0.5)\n",
    "    \"max_gen_len\": 512   # Maximum length of the generated response (default is 512)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfdfe18b-67c4-4262-992f-8a49fe379636",
   "metadata": {},
   "outputs": [
    {
     "ename": "AccessDeniedException",
     "evalue": "An error occurred (AccessDeniedException) when calling the InvokeModel operation: User: arn:aws:sts::794038231401:assumed-role/SageMaker-ExecutionRole-20250401T103257/SageMaker is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:794038231401:inference-profile/us.meta.llama3-2-11b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAccessDeniedException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Invoke the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mbedrock_runtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodelId\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapplication/json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontentType\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapplication/json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Parse and print the response\u001b[39;00m\n\u001b[1;32m     10\u001b[0m response_body \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py:598\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    595\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    596\u001b[0m     )\n\u001b[1;32m    597\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 598\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/context.py:123\u001b[0m, in \u001b[0;36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[1;32m    122\u001b[0m     hook()\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py:1061\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1058\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1059\u001b[0m     )\n\u001b[1;32m   1060\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1063\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mAccessDeniedException\u001b[0m: An error occurred (AccessDeniedException) when calling the InvokeModel operation: User: arn:aws:sts::794038231401:assumed-role/SageMaker-ExecutionRole-20250401T103257/SageMaker is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1:794038231401:inference-profile/us.meta.llama3-2-11b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action"
     ]
    }
   ],
   "source": [
    "# Invoke the model\n",
    "response = bedrock_runtime.invoke_model(\n",
    "    modelId=model_id,\n",
    "    body=body,\n",
    "    accept=\"application/json\",\n",
    "    contentType=\"application/json\"\n",
    ")\n",
    "\n",
    "# Parse and print the response\n",
    "response_body = json.loads(response['body'].read().decode('utf-8'))\n",
    "print(response_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34008a9-dc54-40c7-a51a-4c0f25850cfc",
   "metadata": {},
   "source": [
    "### so the model is not supported without cross region inference. Hence, we use an inference profile\n",
    "\n",
    "### we attach the following policy:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"bedrock:*\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:bedrock:us-east-1:794038231401:inference-profile/us.meta.llama3-2-11b-instruct-v1:0\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"bedrock:*\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-11b-instruct-v1:0\",\n",
    "                \"arn:aws:bedrock:us-west-2::foundation-model/meta.llama3-2-11b-instruct-v1:0\"\n",
    "            ],\n",
    "            \"Condition\": {\n",
    "                \"StringLike\": {\n",
    "                    \"bedrock:InferenceProfileArn\": \"arn:aws:bedrock:us-east-1:794038231401:inference-profile/us.meta.llama3-2-11b-instruct-v1:0\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "166e020c-6d38-4592-b2e1-ae6e816c5e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generation': '\\n\\nThe capital of France is Paris.', 'prompt_token_count': 16, 'generation_token_count': 9, 'stop_reason': 'stop'}\n"
     ]
    }
   ],
   "source": [
    "# Define the model ID for Meta Llama 3.2 11B Instruct\n",
    "model_id = 'us.meta.llama3-2-11b-instruct-v1:0'\n",
    "\n",
    "# Invoke the model\n",
    "response = bedrock_runtime.invoke_model(\n",
    "    modelId=model_id,\n",
    "    body=body,\n",
    "    accept=\"application/json\",\n",
    "    contentType=\"application/json\"\n",
    ")\n",
    "\n",
    "# Parse and print the response\n",
    "response_body = json.loads(response['body'].read().decode('utf-8'))\n",
    "print(response_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177296cc-7151-41f3-979e-2bd2208274fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726e5b36-ac24-4af4-9139-3548d17f59a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
