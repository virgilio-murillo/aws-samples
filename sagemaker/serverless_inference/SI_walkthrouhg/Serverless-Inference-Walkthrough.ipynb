{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fcf8993",
   "metadata": {},
   "source": [
    "# SageMaker Serverless Inference\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61d5a3fa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/serverless-inference|Serverless-Inference-Walkthrough.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b0f7291-3857-4d2d-974f-eb7444898205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.38.35'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4048856b",
   "metadata": {},
   "source": [
    "## XGBoost Regression Example\n",
    "\n",
    "Amazon SageMaker Serverless Inference is a purpose-built inference option that makes it easy for customers to deploy and scale ML models. Serverless Inference is ideal for workloads which have idle periods between traffic spurts and can tolerate cold starts. Serverless endpoints also automatically launch compute resources and scale them in and out depending on traffic, eliminating the need to choose instance types or manage scaling policies.\n",
    "\n",
    "For this notebook we'll be working with the SageMaker XGBoost Algorithm to train a model and then deploy a serverless endpoint. We will be using the public S3 Abalone regression dataset for this example.\n",
    "\n",
    "<b>Notebook Setting</b>\n",
    "- <b>SageMaker Classic Notebook Instance</b>: ml.m5.xlarge Notebook Instance & `conda_python3` Kernel\n",
    "- <b>SageMaker Studio</b>: Python 3 (Data Science)\n",
    "- <b>Regions Available</b>: SageMaker Serverless Inference is currently available in the following regions: US East (Northern Virginia), US East (Ohio), US West (Oregon), EU (Ireland), Asia Pacific (Tokyo) and Asia Pacific (Sydney)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d45aa9a",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- Setup\n",
    "- Model Training\n",
    "- Deployment\n",
    "    - Model Creation\n",
    "    - Endpoint Configuration (Adjust for Serverless)\n",
    "    - Serverless Endpoint Creation\n",
    "    - Endpoint Invocation\n",
    "- Cleanup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ec297d3",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "For testing you need to properly configure your Notebook Role to have <b>SageMaker Full Access</b>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1affea20",
   "metadata": {},
   "source": [
    "Let's start by upgrading the Python SDK, `boto3` and AWS `CLI` (Command Line Interface) packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c500058e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.246.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting botocore\n",
      "  Downloading botocore-1.38.35-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.38.35-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting awscli\n",
      "  Downloading awscli-1.40.34-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: attrs<26,>=24 in ./envi/lib/python3.13/site-packages (from sagemaker) (25.3.0)\n",
      "Collecting cloudpickle>=2.2.1 (from sagemaker)\n",
      "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting docker (from sagemaker)\n",
      "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fastapi (from sagemaker)\n",
      "  Using cached fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting google-pasta (from sagemaker)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting graphene<4,>=3 (from sagemaker)\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting importlib-metadata<7.0,>=1.4.0 (from sagemaker)\n",
      "  Using cached importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: jsonschema in ./envi/lib/python3.13/site-packages (from sagemaker) (4.24.0)\n",
      "Collecting numpy==1.26.4 (from sagemaker)\n",
      "  Using cached numpy-1.26.4-cp313-cp313-linux_x86_64.whl\n",
      "Collecting omegaconf<3,>=2.2 (from sagemaker)\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting packaging<25,>=23.0 (from sagemaker)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: pandas in ./envi/lib/python3.13/site-packages (from sagemaker) (2.3.0)\n",
      "Collecting pathos (from sagemaker)\n",
      "  Using cached pathos-0.3.4-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: platformdirs in ./envi/lib/python3.13/site-packages (from sagemaker) (4.3.8)\n",
      "Collecting protobuf<6.0,>=3.12 (from sagemaker)\n",
      "  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: psutil in ./envi/lib/python3.13/site-packages (from sagemaker) (7.0.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in ./envi/lib/python3.13/site-packages (from sagemaker) (6.0.2)\n",
      "Requirement already satisfied: requests in ./envi/lib/python3.13/site-packages (from sagemaker) (2.32.4)\n",
      "Collecting sagemaker-core<2.0.0,>=1.0.17 (from sagemaker)\n",
      "  Downloading sagemaker_core-1.0.37-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting schema (from sagemaker)\n",
      "  Using cached schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
      "Collecting smdebug-rulesconfig==1.0.1 (from sagemaker)\n",
      "  Using cached smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting tblib<4,>=1.7.0 (from sagemaker)\n",
      "  Using cached tblib-3.1.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting tqdm (from sagemaker)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in ./envi/lib/python3.13/site-packages (from sagemaker) (2.4.0)\n",
      "Collecting uvicorn (from sagemaker)\n",
      "  Downloading uvicorn-0.34.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from botocore)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./envi/lib/python3.13/site-packages (from botocore) (2.9.0.post0)\n",
      "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3)\n",
      "  Downloading s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting docutils<=0.19,>=0.18.1 (from awscli)\n",
      "  Downloading docutils-0.19-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting colorama<0.4.7,>=0.2.5 (from awscli)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting rsa<4.8,>=3.1.2 (from awscli)\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4,>=3->sagemaker)\n",
      "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4,>=3->sagemaker)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7.1 in ./envi/lib/python3.13/site-packages (from graphene<4,>=3->sagemaker) (4.14.0)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<7.0,>=1.4.0->sagemaker)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<3,>=2.2->sagemaker)\n",
      "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.5 in ./envi/lib/python3.13/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.17.0)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<4.8,>=3.1.2->awscli)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pydantic<3.0.0,>=2.0.0 (from sagemaker-core<2.0.0,>=1.0.17->sagemaker)\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting rich<15.0.0,>=14.0.0 (from sagemaker-core<2.0.0,>=1.0.17->sagemaker)\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting mock<5.0,>4.0 (from sagemaker-core<2.0.0,>=1.0.17->sagemaker)\n",
      "  Using cached mock-4.0.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./envi/lib/python3.13/site-packages (from jsonschema->sagemaker) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./envi/lib/python3.13/site-packages (from jsonschema->sagemaker) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./envi/lib/python3.13/site-packages (from jsonschema->sagemaker) (0.25.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./envi/lib/python3.13/site-packages (from requests->sagemaker) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./envi/lib/python3.13/site-packages (from requests->sagemaker) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./envi/lib/python3.13/site-packages (from requests->sagemaker) (2025.4.26)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi->sagemaker)\n",
      "  Using cached starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./envi/lib/python3.13/site-packages (from pandas->sagemaker) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./envi/lib/python3.13/site-packages (from pandas->sagemaker) (2025.2)\n",
      "Collecting ppft>=1.7.7 (from pathos->sagemaker)\n",
      "  Using cached ppft-1.7.7-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting dill>=0.4.0 (from pathos->sagemaker)\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pox>=0.3.6 (from pathos->sagemaker)\n",
      "  Using cached pox-0.3.6-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting multiprocess>=0.70.18 (from pathos->sagemaker)\n",
      "  Using cached multiprocess-0.70.18-py313-none-any.whl.metadata (7.2 kB)\n",
      "Collecting click>=7.0 (from uvicorn->sagemaker)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: h11>=0.8 in ./envi/lib/python3.13/site-packages (from uvicorn->sagemaker) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker)\n",
      "  Using cached pydantic_core-2.33.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./envi/lib/python3.13/site-packages (from rich<15.0.0,>=14.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./envi/lib/python3.13/site-packages (from rich<15.0.0,>=14.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.19.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in ./envi/lib/python3.13/site-packages (from starlette<0.47.0,>=0.40.0->fastapi->sagemaker) (4.9.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./envi/lib/python3.13/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi->sagemaker) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./envi/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=14.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.1.2)\n",
      "Downloading sagemaker-2.246.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\n",
      "Downloading botocore-1.38.35-py3-none-any.whl (13.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m204.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.38.35-py3-none-any.whl (139 kB)\n",
      "Downloading awscli-1.40.34-py3-none-any.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m169.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading docutils-0.19-py3-none-any.whl (570 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.5/570.5 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Using cached importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Downloading s3transfer-0.13.0-py3-none-any.whl (85 kB)\n",
      "Downloading sagemaker_core-1.0.37-py3-none-any.whl (412 kB)\n",
      "Using cached tblib-3.1.0-py3-none-any.whl (12 kB)\n",
      "Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Using cached fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached pathos-0.3.4-py3-none-any.whl (82 kB)\n",
      "Using cached schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading uvicorn-0.34.3-py3-none-any.whl (62 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
      "Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Using cached multiprocess-0.70.18-py313-none-any.whl (151 kB)\n",
      "Using cached pox-0.3.6-py3-none-any.whl (29 kB)\n",
      "Using cached ppft-1.7.7-py3-none-any.whl (56 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Using cached starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: schema, antlr4-python3-runtime, zipp, typing-inspection, tqdm, tblib, smdebug-rulesconfig, pydantic-core, pyasn1, protobuf, ppft, pox, packaging, omegaconf, numpy, mock, jmespath, graphql-core, google-pasta, docutils, dill, colorama, cloudpickle, click, annotated-types, uvicorn, starlette, rsa, rich, pydantic, multiprocess, importlib-metadata, graphql-relay, docker, botocore, s3transfer, pathos, graphene, fastapi, boto3, awscli, sagemaker-core, sagemaker\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.3.0\n",
      "    Uninstalling numpy-2.3.0:\n",
      "      Successfully uninstalled numpy-2.3.0\n",
      "Successfully installed annotated-types-0.7.0 antlr4-python3-runtime-4.9.3 awscli-1.40.34 boto3-1.38.35 botocore-1.38.35 click-8.2.1 cloudpickle-3.1.1 colorama-0.4.6 dill-0.4.0 docker-7.1.0 docutils-0.19 fastapi-0.115.12 google-pasta-0.2.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 importlib-metadata-6.11.0 jmespath-1.0.1 mock-4.0.3 multiprocess-0.70.18 numpy-1.26.4 omegaconf-2.3.0 packaging-24.2 pathos-0.3.4 pox-0.3.6 ppft-1.7.7 protobuf-5.29.5 pyasn1-0.6.1 pydantic-2.11.5 pydantic-core-2.33.2 rich-14.0.0 rsa-4.7.2 s3transfer-0.13.0 sagemaker-2.246.0 sagemaker-core-1.0.37 schema-0.7.7 smdebug-rulesconfig-1.0.1 starlette-0.46.2 tblib-3.1.0 tqdm-4.67.1 typing-inspection-0.4.1 uvicorn-0.34.3 zipp-3.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install sagemaker botocore boto3 awscli --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1cd6f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup clients\n",
    "import boto3\n",
    "\n",
    "client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime = boto3.client(service_name=\"sagemaker-runtime\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aed409fe",
   "metadata": {},
   "source": [
    "### SageMaker Setup\n",
    "To begin, we import the AWS SDK for Python (Boto3) and set up our environment, including an IAM role and an S3 bucket to store our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c5e13f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n",
      "arn:aws:iam::794038231401:role/service-role/AmazonSageMaker-ExecutionRole-20250509T182764\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "boto_session = boto3.session.Session()\n",
    "region = boto_session.region_name\n",
    "print(region)\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "base_job_prefix = \"xgboost-example\"\n",
    "default_bucket_prefix = sagemaker_session.default_bucket_prefix\n",
    "\n",
    "# If a default bucket prefix is specified, append it to the s3 path\n",
    "if default_bucket_prefix:\n",
    "    base_job_prefix = f\"{default_bucket_prefix}/{base_job_prefix}\"\n",
    "\n",
    "role = \"arn:aws:iam::794038231401:role/service-role/AmazonSageMaker-ExecutionRole-20250509T182764\"\n",
    "print(role)\n",
    "\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "s3_prefix = base_job_prefix\n",
    "\n",
    "training_instance_type = \"ml.m5.xlarge\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f634875",
   "metadata": {},
   "source": [
    "Retrieve the Abalone dataset from a publicly hosted S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd1160f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve data\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.download_file(\n",
    "    f\"sagemaker-example-files-prod-{region}\",\n",
    "    \"datasets/tabular/uci_abalone/train_csv/abalone_dataset1_train.csv\",\n",
    "    \"abalone_dataset1_train.csv\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70baa8b0",
   "metadata": {},
   "source": [
    "Upload the Abalone dataset to the default S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81d7425b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./abalone_dataset1_train.csv to s3://sagemaker-us-east-1-794038231401/xgboost-regression/train.csv\n"
     ]
    }
   ],
   "source": [
    "# upload data to S3\n",
    "!aws s3 cp abalone_dataset1_train.csv s3://{default_bucket}/xgboost-regression/train.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "010a6765",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ccffd64",
   "metadata": {},
   "source": [
    "Now, we train an ML model using the XGBoost Algorithm. In this example, we use a SageMaker-provided [XGBoost](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) container image and configure an estimator to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e47bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "training_path = f\"s3://{default_bucket}/xgboost-regression/train.csv\"\n",
    "train_input = TrainingInput(training_path, content_type=\"text/csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eb21f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"s3://{default_bucket}/{s3_prefix}/xgb_model\"\n",
    "\n",
    "# retrieve xgboost image\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.0-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "\n",
    "# Configure Training Estimator\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    output_path=model_path,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "# Set Hyperparameters\n",
    "xgb_train.set_hyperparameters(\n",
    "    objective=\"reg:linear\",\n",
    "    num_round=50,\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.7,\n",
    "    silent=0,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8638fad2",
   "metadata": {},
   "source": [
    "Train the model on the Abalone dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad24755a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2025-06-11-23-42-08-404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-11 23:42:09 Starting - Starting the training job...\n",
      "2025-06-11 23:42:43 Downloading - Downloading input data...\n",
      "2025-06-11 23:43:09 Downloading - Downloading the training image......\n",
      "2025-06-11 23:44:13 Training - Training image download completed. Training in progress.\n",
      "2025-06-11 23:44:13 Uploading - Uploading generated training model\n",
      "2025-06-11 23:44:13 Completed - Training job completed\n",
      "\u001b[34m[2025-06-11 23:43:55.887 ip-10-0-160-101.ec2.internal:7 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value reg:linear to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34m[23:43:55] 2923x8 matrix with 23384 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2025-06-11 23:43:55.955 ip-10-0-160-101.ec2.internal:7 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2025-06-11 23:43:55.955 ip-10-0-160-101.ec2.internal:7 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2025-06-11 23:43:55.956 ip-10-0-160-101.ec2.internal:7 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2025-06-11 23:43:55.957 ip-10-0-160-101.ec2.internal:7 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2025-06-11 23:43:55.957 ip-10-0-160-101.ec2.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mINFO:root:Debug hook created from config\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 2923 rows\u001b[0m\n",
      "\u001b[34m[23:43:55] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\u001b[0m\n",
      "\u001b[34m[23:43:55] WARNING: /workspace/src/learner.cc:328: \u001b[0m\n",
      "\u001b[34mParameters: { num_round, silent } might not be used.\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:8.09123\u001b[0m\n",
      "\u001b[34m[2025-06-11 23:43:55.962 ip-10-0-160-101.ec2.internal:7 INFO hook.py:423] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34m[2025-06-11 23:43:55.965 ip-10-0-160-101.ec2.internal:7 INFO hook.py:486] Hook is writing from the hook with pid: 7\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:6.61298\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:5.45157\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:4.54038\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:3.84707\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:3.31465\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:2.91636\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:2.62415\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:2.40885\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:2.24929\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:2.13106\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:2.04974\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:1.98240\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:1.93888\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:1.89701\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:1.87329\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:1.85216\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:1.82408\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:1.81372\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:1.80362\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:1.78164\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:1.77341\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:1.76766\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:1.75940\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:1.74632\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:1.74385\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:1.73876\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:1.73410\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:1.72847\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:1.72384\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:1.71492\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:1.69789\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:1.69073\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:1.68621\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:1.67960\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:1.67194\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:1.65883\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:1.65463\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:1.65199\u001b[0m\n",
      "\u001b[34m[39]#011train-rmse:1.63903\u001b[0m\n",
      "\u001b[34m[40]#011train-rmse:1.63353\u001b[0m\n",
      "\u001b[34m[41]#011train-rmse:1.62607\u001b[0m\n",
      "\u001b[34m[42]#011train-rmse:1.61662\u001b[0m\n",
      "\u001b[34m[43]#011train-rmse:1.60241\u001b[0m\n",
      "\u001b[34m[44]#011train-rmse:1.59173\u001b[0m\n",
      "\u001b[34m[45]#011train-rmse:1.58875\u001b[0m\n",
      "\u001b[34m[46]#011train-rmse:1.57816\u001b[0m\n",
      "\u001b[34m[47]#011train-rmse:1.56941\u001b[0m\n",
      "\u001b[34m[48]#011train-rmse:1.56063\u001b[0m\n",
      "\u001b[34m[49]#011train-rmse:1.55822\u001b[0m\n",
      "Training seconds: 90\n",
      "Billable seconds: 90\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "xgb_train.fit({\"train\": train_input})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb2f4628",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efabadc5",
   "metadata": {},
   "source": [
    "After training the model, retrieve the model artifacts so that we can deploy the model to an endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "086573fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-794038231401/xgboost-example/xgb_model/sagemaker-xgboost-2025-06-11-23-42-08-404/output/model.tar.gz'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve model data from training job\n",
    "model_artifacts = xgb_train.model_data\n",
    "model_artifacts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93b5dd29",
   "metadata": {},
   "source": [
    "### Model Creation\n",
    "Create a model by providing your model artifacts, the container image URI, environment variables for the container (if applicable), a model name, and the SageMaker IAM role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "466b481a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: xgboost-serverless2025-06-12-12-37-12\n",
      "Model Arn: arn:aws:sagemaker:us-east-1:794038231401:model/xgboost-serverless2025-06-12-12-37-12\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "model_name = \"xgboost-serverless\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Model name: \" + model_name)\n",
    "\n",
    "# dummy environment variables\n",
    "byo_container_env_vars = {\"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"20\", \"SOME_ENV_VAR\": \"myEnvVar\"}\n",
    "\n",
    "create_model_response = client.create_model(\n",
    "    ModelName=model_name,\n",
    "    Containers=[\n",
    "        {\n",
    "            \"Image\": image_uri,\n",
    "            \"Mode\": \"SingleModel\",\n",
    "            \"ModelDataUrl\": model_artifacts,\n",
    "            \"Environment\": byo_container_env_vars,\n",
    "        }\n",
    "    ],\n",
    "    ExecutionRoleArn=role,\n",
    ")\n",
    "\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5a7ac35",
   "metadata": {},
   "source": [
    "### Endpoint Configuration Creation\n",
    "\n",
    "This is where you can adjust the <b>Serverless Configuration</b> for your endpoint. The current max concurrent invocations for a single endpoint, known as `MaxConcurrency`, can be any value from <b>1 to 200</b>, and `MemorySize` can be any of the following: <b>1024 MB, 2048 MB, 3072 MB, 4096 MB, 5120 MB, or 6144 MB</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb84726e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Configuration Arn: arn:aws:sagemaker:us-east-1:794038231401:endpoint-config/xgboost-serverless-epc2025-06-12-12-37-17\n"
     ]
    }
   ],
   "source": [
    "xgboost_epc_name = \"xgboost-serverless-epc\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName=xgboost_epc_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"byoVariant\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"ServerlessConfig\": {\n",
    "                \"MemorySizeInMB\": 1024,\n",
    "                \"MaxConcurrency\": 10,\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Configuration Arn: \" + endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea3321da",
   "metadata": {},
   "source": [
    "### Serverless Endpoint Creation\n",
    "Now that we have an endpoint configuration, we can create a serverless endpoint and deploy our model to it. When creating the endpoint, provide the name of your endpoint configuration and a name for the new endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f9f93e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Arn: arn:aws:sagemaker:us-east-1:794038231401:endpoint/xgboost-serverless-ep2025-06-12-12-37-37\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = \"xgboost-serverless-ep\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=xgboost_epc_name,\n",
    ")\n",
    "\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "831d2181",
   "metadata": {},
   "source": [
    "Wait until the endpoint status is `InService` before invoking the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "335e2ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EndpointName': 'xgboost-serverless-ep2025-06-12-12-37-37',\n",
       " 'EndpointArn': 'arn:aws:sagemaker:us-east-1:794038231401:endpoint/xgboost-serverless-ep2025-06-12-12-37-37',\n",
       " 'EndpointConfigName': 'xgboost-serverless-epc2025-06-12-12-37-17',\n",
       " 'ProductionVariants': [{'VariantName': 'byoVariant',\n",
       "   'DeployedImages': [{'SpecifiedImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3',\n",
       "     'ResolvedImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost@sha256:da43a3b51e4fddd7743132d10eb2578d42c33f1a4d256bb4eaad349d4515b9b7',\n",
       "     'ResolutionTime': datetime.datetime(2025, 6, 12, 6, 37, 38, 328000, tzinfo=tzlocal())}],\n",
       "   'CurrentWeight': 1.0,\n",
       "   'DesiredWeight': 1.0,\n",
       "   'CurrentInstanceCount': 0,\n",
       "   'CurrentServerlessConfig': {'MemorySizeInMB': 1024, 'MaxConcurrency': 10}}],\n",
       " 'EndpointStatus': 'InService',\n",
       " 'CreationTime': datetime.datetime(2025, 6, 12, 6, 37, 37, 598000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2025, 6, 12, 6, 40, 12, 224000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': '7922a86c-b7e0-42a8-a2f0-38e6c214a658',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '7922a86c-b7e0-42a8-a2f0-38e6c214a658',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '819',\n",
       "   'date': 'Thu, 12 Jun 2025 12:49:03 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wait for endpoint to reach a terminal state (InService) using describe endpoint\n",
    "import time\n",
    "\n",
    "describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "while describe_endpoint_response[\"EndpointStatus\"] == \"Creating\":\n",
    "    describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(describe_endpoint_response[\"EndpointStatus\"])\n",
    "    time.sleep(15)\n",
    "\n",
    "describe_endpoint_response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bdd1d0a4",
   "metadata": {},
   "source": [
    "### Endpoint Invocation\n",
    "Invoke the endpoint by sending a request to it. The following is a sample data point grabbed from the CSV file downloaded from the public Abalone dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2c93e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'4.566554546356201'\n"
     ]
    }
   ],
   "source": [
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=b\".345,0.224414,.131102,0.042329,.279923,-0.110329,-0.099358,0.0\",\n",
    "    ContentType=\"text/csv\",\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98c1b576-7d21-4e37-a9ca-972fe2a95c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample payload uploaded to s3://sagemaker-us-east-1-794038231401/xgboost-regression/payload.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import tarfile\n",
    "import os\n",
    "\n",
    "# Assuming default_bucket is defined\n",
    "# If not, replace with actual bucket name\n",
    "# default_bucket = \"your-bucket-name\"\n",
    "\n",
    "training_path = f\"s3://{default_bucket}/xgboost-regression/train.csv\"\n",
    "\n",
    "# Download the training data\n",
    "s3 = boto3.client('s3')\n",
    "bucket, key = training_path.replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "data = obj['Body'].read().decode('utf-8')\n",
    "\n",
    "# Read into pandas DataFrame\n",
    "df = pd.read_csv(StringIO(data), header=None)\n",
    "\n",
    "# For XGBoost, first column is target, so features are from column 1 onwards\n",
    "features = df.iloc[:, 1:]\n",
    "\n",
    "# Select a subset, say first 10 rows\n",
    "sample_df = features.head(10)\n",
    "\n",
    "# Save to local CSV\n",
    "local_csv = \"sample.csv\"\n",
    "sample_df.to_csv(local_csv, index=False, header=False)\n",
    "\n",
    "# Create tar.gz file\n",
    "local_tar = \"payload.tar.gz\"\n",
    "with tarfile.open(local_tar, \"w:gz\") as tar:\n",
    "    tar.add(local_csv, arcname=os.path.basename(local_csv))\n",
    "\n",
    "# Upload to S3\n",
    "sample_key = \"xgboost-regression/payload.tar.gz\"\n",
    "s3.upload_file(local_tar, bucket, sample_key)\n",
    "\n",
    "sample_payload_url = f\"s3://{bucket}/{sample_key}\"\n",
    "print(f\"Sample payload uploaded to {sample_payload_url}\")\n",
    "\n",
    "# Optionally, clean up local files\n",
    "os.remove(local_csv)\n",
    "os.remove(local_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d8a2361b-96b4-4730-8c51-06b3ed2b96cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "# Initialize SageMaker client\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "# Specify the endpoint config name\n",
    "endpoint_config_name = 'xgboost-serverless-epc2025-06-11-23-56-50'\n",
    "\n",
    "# Get the model name from the endpoint config\n",
    "response = sagemaker_client.describe_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "model_name = response['ProductionVariants'][0]['ModelName']\n",
    "\n",
    "# Specify the IAM role ARN\n",
    "role_arn = role\n",
    "\n",
    "from datetime import datetime\n",
    "job_name = f'my-serverless-recommendation-job-{int(datetime.now().timestamp())}'\n",
    "\n",
    "response = sagemaker_client.create_inference_recommendations_job(\n",
    "    JobName=job_name,\n",
    "    JobType='Advanced',\n",
    "    RoleArn=role_arn,\n",
    "    StoppingConditions= {\n",
    "        'MaxInvocations': 10000,  # Maximum requests per minute to test\n",
    "        'ModelLatencyThresholds': [\n",
    "            {\n",
    "                'Percentile': 'P95',  # 95th percentile latency\n",
    "                'ValueInMilliseconds': 1000  # Stop if latency exceeds 100ms\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    InputConfig={\n",
    "        'ModelName': model_name,\n",
    "        'EndpointConfigurations': [\n",
    "            {\n",
    "                'ServerlessConfig': {\n",
    "                    'MemorySizeInMB': 1024,\n",
    "                    'MaxConcurrency': 200\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'ServerlessConfig': {\n",
    "                    'MemorySizeInMB': 2048,\n",
    "                    'MaxConcurrency': 200\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'ServerlessConfig': {\n",
    "                    'MemorySizeInMB': 4096,\n",
    "                    'MaxConcurrency': 200\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        'ContainerConfig': {\n",
    "            'Framework': 'XGBoost',\n",
    "            'FrameworkVersion': '1.0-1',\n",
    "            'PayloadConfig': {\n",
    "                'SamplePayloadUrl': sample_payload_url,\n",
    "                'SupportedContentTypes': ['text/csv']\n",
    "            }\n",
    "        },\n",
    "        'JobDurationInSeconds': 15000,\n",
    "        \"TrafficPattern\": {\n",
    "            \"TrafficType\": \"STAIRS\",\n",
    "            \"Stairs\": { \n",
    "                    \"DurationInSeconds\": 120,\n",
    "                    \"NumberOfSteps\": 60,\n",
    "                    \"UsersPerStep\": 3\n",
    "                }\n",
    "        },\n",
    "        'ResourceLimit': {\n",
    "            'MaxNumberOfTests': 10,\n",
    "            'MaxParallelOfTests': 5\n",
    "        },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f9103a05-274e-47aa-a87b-6359d0d1cc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference recommendation job created: arn:aws:sagemaker:us-east-1:794038231401:inference-recommendations-job/my-serverless-recommendation-job-1749749311\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "MemorySizeInMB: 2048, MaxConcurrency: 200\n",
      "Metrics: {'CostPerHour': 0.14399999380111694, 'CostPerInference': 1.8453022221365245e-07, 'MaxInvocations': 13006, 'ModelLatency': 4, 'MemoryUtilization': 17.245738983154297, 'ModelSetupTime': 5700835}\n",
      "MemorySizeInMB: 1024, MaxConcurrency: 200\n",
      "Metrics: {'CostPerHour': 0.07199999690055847, 'CostPerInference': 8.48476275905341e-08, 'MaxInvocations': 14143, 'ModelLatency': 4, 'MemoryUtilization': 34.49601364135742, 'ModelSetupTime': 9285322}\n",
      "MemorySizeInMB: 4096, MaxConcurrency: 200\n",
      "Metrics: {'CostPerHour': 0.2879999876022339, 'CostPerInference': 3.4762456380121876e-07, 'MaxInvocations': 13808, 'ModelLatency': 4, 'MemoryUtilization': 11.093599319458008, 'ModelSetupTime': 5410191}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Inference recommendation job created: {response['JobArn']}\")\n",
    "\n",
    "# Wait for the job to complete\n",
    "while True:\n",
    "    response = sagemaker_client.describe_inference_recommendations_job(JobName=job_name)\n",
    "    status = response['Status']\n",
    "    if status in ['COMPLETED', 'FAILED', 'STOPPED']:\n",
    "        break\n",
    "    print(f\"Job status: {status}\")\n",
    "    time.sleep(60)\n",
    "\n",
    "if status == 'COMPLETED':\n",
    "    recommendations = response['InferenceRecommendations']\n",
    "    for rec in recommendations:\n",
    "        if 'ServerlessConfig' in rec['EndpointConfiguration']:\n",
    "            serverless_config = rec['EndpointConfiguration']['ServerlessConfig']\n",
    "            memory_size = serverless_config['MemorySizeInMB']\n",
    "            max_concurrency = serverless_config['MaxConcurrency']\n",
    "            metrics = rec['Metrics']\n",
    "            print(f\"MemorySizeInMB: {memory_size}, MaxConcurrency: {max_concurrency}\")\n",
    "            print(f\"Metrics: {metrics}\")\n",
    "else:\n",
    "    print(f\"Job did not complete successfully. Status: {status}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de35dc1e",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "Delete any resources you created in this notebook that you no longer wish to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e895a46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_model(ModelName=model_name)\n",
    "client.delete_endpoint_config(EndpointConfigName=xgboost_epc_name)\n",
    "client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b98fea79",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/serverless-inference|Serverless-Inference-Walkthrough.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/serverless-inference|Serverless-Inference-Walkthrough.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/serverless-inference|Serverless-Inference-Walkthrough.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/serverless-inference|Serverless-Inference-Walkthrough.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/serverless-inference|Serverless-Inference-Walkthrough.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/serverless-inference|Serverless-Inference-Walkthrough.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/serverless-inference|Serverless-Inference-Walkthrough.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/serverless-inference|Serverless-Inference-Walkthrough.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/serverless-inference|Serverless-Inference-Walkthrough.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/serverless-inference|Serverless-Inference-Walkthrough.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/serverless-inference|Serverless-Inference-Walkthrough.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/serverless-inference|Serverless-Inference-Walkthrough.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/serverless-inference|Serverless-Inference-Walkthrough.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/serverless-inference|Serverless-Inference-Walkthrough.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/serverless-inference|Serverless-Inference-Walkthrough.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
